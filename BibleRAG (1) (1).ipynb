{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RsHQQwQGx1B"
      },
      "outputs": [],
      "source": [
        "# Bismillah"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "!pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "!pip install faiss-cpu\n",
        "!pip install rank_bm25\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "!pip install -U langchain-community\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.retrievers import BM25Retriever\n",
        "from langchain.schema import Document\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "rqjXEv-aG_FA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce368514-b32a-4204-a89b-6f55b627970a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n",
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.52)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.31)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.21 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the data\n",
        "loader = TextLoader(\"/bible.txt\")\n",
        "# raw_documents = loader.load() # was doing this before, but resulted in each\n",
        "                                # individual line being its own document, not\n",
        "                                # big enough for chunking, so instead took whole\n",
        "                                # bible as single document.\n",
        "                                # Can also take multiple verses as a single doc.\n",
        "\n",
        "raw_lines = loader.load()\n",
        "merged_text = \" \".join([doc.page_content.strip() for doc in raw_lines])\n",
        "raw_documents = [Document(page_content=merged_text)]\n"
      ],
      "metadata": {
        "id": "jBoj8_rOG_2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunking Configurations\n",
        "# [256, 512, 1024, 2048]\n",
        "chunk_sizes = [256]\n",
        "\n",
        "# Number of documents to retrieve\n",
        "doc_retrieval_counts = [3, 5, 10]\n",
        "\n",
        "# Embedding Methods\n",
        "embedding_methods = [\"bge-small-en\", \"paraphrase-MiniLM-L6-v2\", \"all-MiniLM-L6-v2\"]"
      ],
      "metadata": {
        "id": "si7EcsPIHCzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLMs setup\n",
        "def load_llm(model_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    return pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=5000, do_sample=False)"
      ],
      "metadata": {
        "id": "Yhlhc0Wf7du2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_models = {\n",
        "    # \"Falcon3-1B-Instruct\" : load_llm(\"tiiuae/Falcon3-1B-Instruct\"),\n",
        "    \"Qwen2.5-1.5B-Instruct\": load_llm(\"Qwen/Qwen2.5-1.5B-Instruct\"),\n",
        "}"
      ],
      "metadata": {
        "id": "gTJaxS5X7o3S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227,
          "referenced_widgets": [
            "66de3012530e44ed812a585638f8f669",
            "34ef6f496d864756a085430a85264709",
            "34d0ddafef844e488b16ba0eb80863f4",
            "15a002e43f4e4b9b926f99c5cdfc742a",
            "d320608256344ac49a3bb2e3d8536118",
            "9edde0c3a5e54c8c8d78683d25428387",
            "001065fe0a534e36ae24ae8f443ff9c3",
            "c224e7b6a99f4cab8e0299cd8e7f269f",
            "72a09017e5df40b1b5dbdb661b2ca9bc",
            "91097235cbf14c27a954c8c97b8b7b84",
            "944252acd10a48e6b3279060ae13a09f",
            "fad2fb4a0487443caf8fd2e4549a6e1c",
            "ab3d3cbfe3f24ea1ad8d28c553216f77",
            "3646d1d3deb6488297e7bcb1044d3ef1",
            "f57c37aa0f1a461787c7ba4899441e3f",
            "7152fde90abd4be59af35bd8e4e4127e",
            "461c6e270fa941909b09995806651e19",
            "0f509cefdef74093b761439a3abddcc1",
            "c68b0debc0af487685b136f8647aa7ef",
            "bcb8bbc9052f45c78e898e3be91c00d5",
            "14c78840f2374d959fa1b53ad527797a",
            "2068cfa72713419abd0882d3fdb003e7",
            "24a28947a97f48078664feeb573ca2fd",
            "a38eb481e44c4710bcefb95494914a9c",
            "a511052f82074eef92f3d0ee615ecfa9",
            "d82bd65e75ec45fea3ff2aaa7c0d4b8e",
            "452929bf738a4f768812cf06048b004b",
            "b10faac3a1394b299718476e4fd42aef",
            "727d9be3c6ea4a0384984580122a6e90",
            "e8420b05027e44ceb0e006b764fd23b3",
            "34e95b1d337441009356bd9b853516df",
            "b406cc196e5f425b94eb0786159a7722",
            "80a279ef1f2a48979ca2c4eb586f028f",
            "e05aabe2046e472a98c9dafd1d930e58",
            "cbbab4e68c22467086d4b55ddda4a6c9",
            "282193442d7d4f0b89f81123fdfe09b8",
            "4e5de8bfff24494eaacf02d4e21d00d0",
            "ca4bf0c41d4b436783c5bee5c3ba4f40",
            "7d838c5bb04741e38d43864ba3386f6e",
            "1d0a603e4b8b4fa581b397175ec42bbd",
            "be4d39fa5d0a484e8878858e91466a80",
            "61d0276cc953483d9fe0f80bebc04f54",
            "648f98ed29044e5eb03e27ceba585a9c",
            "96a4bb718b2e40da99fca33bd61ce349",
            "9d37465ce6344c909317d41f687d85eb",
            "44af5e03a6c94ddc8d3cb4b6d7f6aa56",
            "1cfa46cec82e472f856cc34432f93fd3",
            "21a368abb1fd44d19cac3e110778714a",
            "4b42d04965a447f58c60ca62b14513f8",
            "2aa1fefc21e64ace94a17e53da99a742",
            "14bab020c77542a5bce3d50d92d17f2c",
            "b26dd6d69f184f02b500efe87659ecd0",
            "e61dbebaa5534a148ca2a2ec3b61507f",
            "56494079f56d4ec2a7d0042862532800",
            "746d9ff3a7254ba9824c35c3e0237620",
            "7cf9234914fd4d559eec98215612c7bb",
            "1aea218f191c4b0f9afd31c3490fae96",
            "9a51a28c627e49d5be67a9b5e5399734",
            "07773ce4cb3648308dac70dd813c9d56",
            "9c3790ad5f5e4da1b6e85f254ab21b15",
            "31876d9d2a00467b86d763d2f92d448d",
            "560427d6cd4348f2bbd6248db0039317",
            "df2c3ac7efca4e4da6ac64bc80ab0fbb",
            "f918d0a4a5fd41b39feb099dfe8d4131",
            "7eef14ac94164872929475c4ac76269e",
            "f9c57fbac39342129b288bdb137aa6d4"
          ]
        },
        "outputId": "c581bb3f-3149-4e20-e9ce-c1b89440eb3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/365k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66de3012530e44ed812a585638f8f669"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fad2fb4a0487443caf8fd2e4549a6e1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/826 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24a28947a97f48078664feeb573ca2fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/656 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e05aabe2046e472a98c9dafd1d930e58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d37465ce6344c909317d41f687d85eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/113 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cf9234914fd4d559eec98215612c7bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vectorstore(docs, method):\n",
        "    model_map = {\n",
        "        \"bge-small-en\": \"BAAI/bge-small-en\",\n",
        "        \"paraphrase-MiniLM-L6-v2\": \"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
        "        \"all-MiniLM-L6-v2\": \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "    }\n",
        "    model_name = model_map[method]\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "    return FAISS.from_documents(docs, embeddings), SentenceTransformer(model_name)"
      ],
      "metadata": {
        "id": "WaI9TF0g7tP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function: Apply Reciprocal Rank Fusion (RRF) - Used by Hybrid_RRF_Search() below\n",
        "def rrf_fusion(retrieval_results, k=60, top_k=5):\n",
        "    scores = {}\n",
        "    for results in retrieval_results:\n",
        "        for rank, doc in enumerate(results):\n",
        "            doc_id = doc.page_content\n",
        "            scores[doc_id] = scores.get(doc_id, 0) + 1 / (rank + k)\n",
        "    sorted_docs = sorted(scores.keys(), key=lambda doc_id: scores[doc_id], reverse=True)\n",
        "    return [Document(page_content=doc_id) for doc_id in sorted_docs[:top_k]]"
      ],
      "metadata": {
        "id": "wuvdrfQFLLYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def pad_documents(docs, all_docs, k):\n",
        "#     \"\"\"\n",
        "#     Ensure k documents are returned. Pad with unused docs if needed.\n",
        "#     Returns: (padded_docs, was_padded)\n",
        "#     \"\"\"\n",
        "#     if len(docs) >= k:\n",
        "#         return docs[:k], False\n",
        "\n",
        "#     seen = set(doc.page_content for doc in docs)\n",
        "#     padding = [doc for doc in all_docs if doc.page_content not in seen]\n",
        "#     padded_docs = docs + padding[:k - len(docs)]\n",
        "#     return padded_docs, True\n",
        "\n",
        "\n",
        "# Retrieval Method Functions\n",
        "def bm25_search(question, documents, k):\n",
        "    retriever = BM25Retriever.from_documents(documents)\n",
        "    return retriever.get_relevant_documents(question)[:k]\n",
        "# def bm25_search(question, documents, k):\n",
        "#     retriever = BM25Retriever.from_documents(documents)\n",
        "#     results = retriever.get_relevant_documents(question)\n",
        "#     return pad_documents(results, documents, k)\n",
        "\n",
        "\n",
        "def mmr_search(question, vectorstore, k):\n",
        "    retriever = vectorstore.as_retriever(search_type=\"mmr\")\n",
        "    return retriever.get_relevant_documents(question)[:k]\n",
        "# def mmr_search(question, vectorstore, k, all_docs):\n",
        "#     retriever = vectorstore.as_retriever(search_type=\"mmr\")\n",
        "#     results = retriever.get_relevant_documents(question)\n",
        "#     return pad_documents(results, all_docs, k)\n",
        "\n",
        "\n",
        "def semantic_search(question, vectorstore, k):\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    return retriever.get_relevant_documents(question)[:k]\n",
        "# def semantic_search(question, vectorstore, k, all_docs):\n",
        "#     retriever = vectorstore.as_retriever()\n",
        "#     results = retriever.get_relevant_documents(question)\n",
        "#     return pad_documents(results, all_docs, k)\n",
        "\n",
        "\n",
        "# def hybrid_rrf_search(question, documents, vectorstore, k):\n",
        "#     bm25 = bm25_search(question, documents, k)\n",
        "#     sem = semantic_search(question, vectorstore, k)\n",
        "#     mmr = mmr_search(question, vectorstore, k)\n",
        "#     return rrf_fusion([bm25, sem], top_k = k)# mmr], top_k=k)\n",
        "\n",
        "def hybrid_rrf_search(precomputed_results, k):\n",
        "    return rrf_fusion([precomputed_results[\"BM25\"], precomputed_results[\"Semantic\"], precomputed_results[\"MMR\"]], top_k=k)\n",
        "# def hybrid_rrf_search(precomputed_results, all_docs, k):\n",
        "#     fused = rrf_fusion([precomputed_results[\"BM25\"], precomputed_results[\"Semantic\"], precomputed_results[\"MMR\"]], top_k=k)\n",
        "#     return pad_documents(fused, all_docs, k)\n"
      ],
      "metadata": {
        "id": "ODVuPvUf7uEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used by ragas - Needs to be generated on a seperate run.\n",
        "# def generate_ground_truth(question, docs):\n",
        "#     context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "#     pipeline_gt = load_llm(\"Qwen/Qwen2.5-1.5B-Instruct\")  # Different model from the tested ones\n",
        "#     response = pipeline_gt(f\"\"\"You are a Bible expert. Using strictly and only the context provided below, answer the question factually in a detailed paragraph. Do not add personal thoughts, opinions, or explanations.\n",
        "#                 Context:\n",
        "#                 {context}\n",
        "\n",
        "#                 Question: {question}\n",
        "#                 Answer: \"\"\")[0]['generated_text']\n",
        "#     return response"
      ],
      "metadata": {
        "id": "S1msVOST7xTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function: Evaluate Response\n",
        "# def evaluate_response(question, response, retrieved_docs, ground_truth):\n",
        "#     context_strs = [doc.page_content for doc in retrieved_docs]\n",
        "#     data = {\n",
        "#         \"question\": [question],\n",
        "#         \"contexts\": [context_strs],\n",
        "#         \"answer\": [response],\n",
        "#         \"ground_truth\": [ground_truth]\n",
        "#     }\n",
        "#     ragas_dataset = Dataset.from_dict(data)\n",
        "#     scores = evaluate(ragas_dataset, metrics=[faithfulness, answer_relevancy])\n",
        "#     return float(scores[\"faithfulness\"][0]), float(scores[\"answer_relevancy\"][0])\n",
        "\n",
        "def evaluate_response(question, response, retrieved_docs, ground_truth, embedder):\n",
        "    answer_vec = embedder.encode([response])\n",
        "    # context_vec = embedder.encode([\" \".join(retrieved_docs)])\n",
        "    context_vec = embedder.encode([\" \".join([doc.page_content for doc in retrieved_docs])])\n",
        "    question_vec = embedder.encode([question])\n",
        "    true_answer_vec = embedder.encode([ground_truth])\n",
        "\n",
        "    faithfulness = cosine_similarity(answer_vec, context_vec)[0][0]\n",
        "    relevance = cosine_similarity(answer_vec, question_vec)[0][0]\n",
        "    simAnswer = cosine_similarity(answer_vec, true_answer_vec)[0][0]\n",
        "    return {\n",
        "        \"faithfulness\": round(faithfulness, 4),\n",
        "        \"relevance\": round(relevance, 4),\n",
        "        \"similarity\": round(simAnswer, 4)\n",
        "    }"
      ],
      "metadata": {
        "id": "LFjEIZXN7zo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_retrieved_docs(docs):\n",
        "    return \"\\n\\n\".join([f\"[{i+1}] {doc.page_content}\" for i, doc in enumerate(docs)])"
      ],
      "metadata": {
        "id": "OIg5vcPV718x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results = []\n",
        "# question = \"What does the Bible say about forgiveness?\"\n",
        "\n",
        "# Questions and answers\n",
        "questions_and_answers = [\n",
        "    {\"question\": \"What does the Bible say about forgiveness?\",\n",
        "     \"ground_truth\": f\"\"\"The Bible presents forgiveness as a central theme in the relationship between God and humanity, as well as among individuals. From Genesis to Revelation, forgiveness reveals God’s mercy, His justice, and the call for believers to live in harmony with others through grace and compassion.\n",
        "      God’s forgiveness is abundant and freely offered to those who repent. Throughout Scripture, God is portrayed as merciful, slow to anger, and ready to pardon. For example, 1 John 1:9 affirms, “If we confess our sins, he is faithful and just to forgive us our sins, and to cleanse us from all unrighteousness.” This promise shows that forgiveness is not earned by works, but received through confession and faith in God’s righteousness. Similarly, Psalm 103:12 expresses the completeness of God's forgiveness: “As far as the east is from the west, so far hath he removed our transgressions from us.” God’s forgiveness restores fellowship with Him and gives peace to the repentant heart.\n",
        "      Christians are also called to forgive others, as a reflection of the forgiveness they have received. Ephesians 4:32 commands, “And be ye kind one to another, tenderhearted, forgiving one another, even as God for Christ's sake hath forgiven you.” This reveals that forgiveness is not merely an act of courtesy but a divine obligation rooted in the work of Christ. Jesus emphasized this in the Lord’s Prayer, stating in Matthew 6:14-15 that if we do not forgive others, our own forgiveness from God is hindered. Forgiveness is thus not optional—it is evidence of a transformed heart.\n",
        "      Jesus also taught that forgiveness should be unlimited and sincere. When Peter asked how many times he should forgive someone, Jesus replied, “Until seventy times seven” (Matthew 18:22), indicating that there should be no limit to our willingness to forgive. This teaching is reinforced in the parable of the unforgiving servant (Matthew 18:23-35), where a man forgiven a great debt by his master refuses to forgive a small debt owed to him. The master’s judgment illustrates God’s displeasure when forgiven people harbor unforgiveness.\n",
        "      Finally, forgiveness is made possible through the atoning sacrifice of Jesus Christ. The cross stands as the ultimate expression of God’s love and forgiveness. Acts 13:38-39 proclaims that through Jesus, forgiveness of sins is preached and all who believe are justified. The believer’s assurance of pardon is rooted in Christ’s finished work, which not only cleanses the soul but also empowers the believer to forgive others.\n",
        "      In sum, forgiveness in the Bible is a divine gift that believers are to receive and extend. It is foundational to Christian faith and essential to walking in the love and grace of God.\"\"\"},\n",
        "    {\"question\": \"What is the greatest commandment?\",\n",
        "     \"ground_truth\": f\"\"\"The greatest commandment, according to Jesus Christ, is to love God with all one’s being. When asked by a Pharisee which commandment in the law was the greatest, Jesus responded in Matthew 22:37-38 (KJV), “Thou shalt love the Lord thy God with all thy heart, and with all thy soul, and with all thy mind. This is the first and great commandment.” This commandment is a quotation from Deuteronomy 6:5, a foundational verse in the Old Testament known as part of the Shema, which was recited daily by faithful Jews. It emphasizes total devotion to God, involving every part of a person—their emotions, soul, and intellect. Loving God fully is the highest priority and the foundation of all obedience in the believer’s life.\n",
        "      Jesus went on to say that the second commandment is closely related: “And the second is like unto it, Thou shalt love thy neighbour as thyself” (Matthew 22:39). This commandment, drawn from Leviticus 19:18, teaches that genuine love for God will naturally result in love for others. It reflects the outworking of divine love in human relationships. Jesus concluded by saying, “On these two commandments hang all the law and the prophets” (Matthew 22:40), meaning that all the moral teachings of Scripture are rooted in these two principles. They encapsulate the entire moral will of God as revealed in the Law and the Prophets.\n",
        "      Together, these commandments reveal that true obedience to God is not just about external rituals or legalistic rule-keeping, but about a heart transformed by love. Loving God with all one's heart and loving others as oneself sums up the Christian ethic and forms the basis for all other commandments. These two principles guide the believer’s conduct, showing that love is both the motive and the measure of spiritual maturity.\"\"\"},\n",
        "    {\"question\": \"What is the Bible's view on wealth and poverty?\",\n",
        "     \"ground_truth\": f\"\"\"The Bible addresses the themes of wealth and poverty with deep spiritual insight, offering guidance on how both should be viewed in light of God’s kingdom. Wealth itself is not condemned, but the misuse of it, the love of it, and trust in riches are strongly warned against. Conversely, poverty is not praised for its own sake, but the poor are often depicted as those whom God defends and blesses when they remain faithful.\n",
        "      Scripture teaches that all wealth ultimately belongs to God, and humans are stewards of what He provides. Deuteronomy 8:18 (KJV) states, “But thou shalt remember the LORD thy God: for it is he that giveth thee power to get wealth.” Wealth, therefore, should be handled with gratitude and responsibility. The danger lies not in having riches, but in letting them become a source of pride or idolatry. 1 Timothy 6:10 warns, “For the love of money is the root of all evil,” showing that an improper attachment to riches can lead to spiritual ruin. Jesus also taught, “Ye cannot serve God and mammon” (Matthew 6:24), emphasizing the incompatibility of serving both God and wealth.\n",
        "      On the other hand, the Bible consistently upholds a concern for the poor and needy. God is described as their defender and provider. Proverbs 19:17 (KJV) says, “He that hath pity upon the poor lendeth unto the LORD; and that which he hath given will he pay him again.” Acts of generosity are not merely social duties but are considered acts of righteousness before God. The Law, the Prophets, and the teachings of Jesus call for justice, compassion, and active care for the poor. In the ministry of Jesus, the poor often received His special attention. In Luke 4:18, Jesus said He was sent to “preach the gospel to the poor,” signaling their significance in God’s redemptive plan.\n",
        "      Importantly, Jesus taught that true riches are spiritual and not material. In Luke 12:15, He warned, “Take heed, and beware of covetousness: for a man's life consisteth not in the abundance of the things which he possesseth.” Christians are encouraged to seek treasures in heaven, not on earth (Matthew 6:19-21), reflecting an eternal perspective. Those who are rich are exhorted to be generous and not high-minded, recognizing their accountability to God (1 Timothy 6:17-19).\n",
        "      In conclusion, the Bible presents a balanced view of wealth and poverty. Wealth is not inherently sinful, but it must be managed with humility, generosity, and a heart submitted to God. Poverty is not a curse when coupled with godliness, and the poor are often shown to be spiritually rich in faith. Both conditions are opportunities to glorify God, either by using wealth for His purposes or by trusting Him in need.\"\"\"\n",
        "    },\n",
        "    {\"question\": \"Explain the concept of grace in the Bible.\",\n",
        "     \"ground_truth\": f\"\"\"The concept of grace in the Bible is foundational to the message of salvation and Christian life. Grace refers to the unmerited favor of God toward sinners. It is God’s loving kindness extended to humanity, not because of any worth or works of their own, but because of His own mercy and purpose. The clearest expression of grace is found in the person and work of Jesus Christ, through whom salvation is freely offered to all who believe.\n",
        "     Scripture declares that salvation is by grace, not by works. Ephesians 2:8-9 (KJV) states, “For by grace are ye saved through faith; and that not of yourselves: it is the gift of God: Not of works, lest any man should boast.” This passage highlights that grace is a gift—it cannot be earned, deserved, or bought. It is entirely the result of God’s initiative. Romans 11:6 further affirms, “And if by grace, then is it no more of works: otherwise grace is no more grace.” Grace thus magnifies God's sovereignty and love, while humbling the sinner before Him.\n",
        "     Grace is also transformative, not merely a covering for sin. Titus 2:11-12 (KJV) teaches, “For the grace of God that bringeth salvation hath appeared to all men, Teaching us that, denying ungodliness and worldly lusts, we should live soberly, righteously, and godly, in this present world.” True grace changes the heart and empowers the believer to live a holy life. It instructs, sanctifies, and sustains the Christian throughout their journey. Grace does not excuse sin; rather, it enables victory over sin through the power of the Holy Spirit.\n",
        "     Furthermore, grace is abundant and available to all, regardless of background or past sin. The Apostle Paul, once a persecutor of the church, described himself as a chief example of God's grace. In 1 Corinthians 15:10, he said, “But by the grace of God I am what I am: and his grace which was bestowed upon me was not in vain.” His life was radically changed by God’s grace, demonstrating that no one is beyond its reach.\n",
        "     In summary, grace in the Bible is the generous, unearned favor of God extended to undeserving sinners. It is the basis of salvation, the power for holy living, and the expression of God’s infinite love. Grace exalts God as the giver and sustainer of life and calls the believer to live in gratitude and obedience.\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Results\n",
        "results = []"
      ],
      "metadata": {
        "id": "qVQn9ErSMrKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating ground truth to be used for evaluation by ragas\n",
        "# splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
        "# docs_for_eval = splitter.split_documents(raw_documents)\n",
        "# for i, doc in enumerate(docs_for_eval[:5]):\n",
        "#     print(f\"Chunk {i+1} ({len(doc.page_content)} chars):\\n{doc.page_content}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# Ground Truth for \"Forgiveness\" question by Falcon1B\n",
        "# The Bible presents forgiveness as a central theme, particularly in the context of personal relationships and spiritual growth. It emphasizes the importance of extending forgiveness to others, as seen in Mark 11:25-27, where Jesus teaches the necessity of forgiving one's enemies to receive divine forgiveness. This is further reinforced in Ephesians 1:7-9, where the concept of redemption through Christ's blood is highlighted, and in Matthew 6:11-14, where the practice of forgiving others is encouraged, with the understanding that forgiveness is a gift from God and is reciprocated by divine forgiveness.\n",
        "\n",
        "# The Bible also underscores the role of forgiveness in maintaining spiritual health and harmony. In 2 Corinthians 2:9-11, Paul emphasizes the need for believers to forgive others, as it is a demonstration of their faith and commitment to Christ. This act of forgiveness is not only a response to the forgiveness extended by God but also a means to strengthen one's own spiritual resolve and resist the temptations of sin.\n",
        "\n",
        "# Furthermore, the Bible teaches that forgiveness is not merely a personal act but a communal one, as seen in Ephesians 4:32, where believers are called to forgive one another, reflecting the unity and love within the Christian community. This communal aspect of forgiveness is crucial for building a supportive and loving environment, as it mirrors the love and reconciliation God desires among His followers.\n",
        "\n",
        "# In summary, the Bible teaches that forgiveness is a profound act of love and grace, essential for both personal spiritual growth and the health of the Christian community. It is a practice that requires self-awareness, humility, and a deep understanding of God's boundless mercy and forgiveness. Through forgiveness, believers are encouraged to emulate Christ's example, fostering a spirit of reconciliation and unity in their relationships with others and with God.\n",
        "###############################################\n",
        "################################################\n",
        "#################################################\n",
        "\n",
        "# Ground Truth for \"Forgiveness\" question by Qwen2.5-1.5B\n",
        "# The Bible teaches that forgiveness is essential for spiritual growth and unity with God.\n",
        "# It emphasizes the importance of forgiving others, both within oneself and towards those who wronged them.\n",
        "# Forgiveness allows individuals to move past hurtful experiences and fosters reconciliation between people.\n",
        "# This concept is further emphasized by Jesus' teachings in Matthew 6:14-15, where He states that if one forgives others, God will forgive them as well.\n",
        "# Additionally, Paul's letter to the Ephesians highlights the divine nature of forgiveness, stating that God has given believers redemption through His blood and has forgiven them according to His grace.\n",
        "# These verses underscore the significance of forgiveness in Christian theology and its role in maintaining harmony among believers.\n",
        "# Furthermore, 2 Corinthians 2:9-11 underscores the need for forgiveness in relationships, suggesting that forgiveness can protect individuals from being used by Satan.\n",
        "# Overall, the Bible portrays forgiveness as a fundamental aspect of faith and spirituality, promoting healing and unity within communities.\n",
        "###################################################\n",
        "####################################################\n",
        "########################################################\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EQVc7vmX735K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# general testing to see the chunking works\n",
        "for chunk_size in chunk_sizes:\n",
        "    print(\"Chunk Size: \", chunk_size)\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=50)\n",
        "    docs = splitter.split_documents(raw_documents)\n",
        "    for i, doc in enumerate(docs[21:45]):\n",
        "        print(f\"Chunk {i+1} ({len(doc.page_content)} chars):\\n{doc.page_content}\\n\")\n",
        "    print(\"--------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "jdybFvHOiALN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0811cc16-02d3-4660-c4d8-e70a5562d0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk Size:  256\n",
            "Chunk 1 (217 chars):\n",
            "Genesis 1:29\tAnd God said, Behold, I have given you every herb bearing seed, which [is] upon the face of all the earth, and every tree, in the which [is] the fruit of a tree yielding seed; to you it shall be for meat.\n",
            "\n",
            "Chunk 2 (206 chars):\n",
            "Genesis 1:30\tAnd to every beast of the earth, and to every fowl of the air, and to every thing that creepeth upon the earth, wherein [there is] life, [I have given] every green herb for meat: and it was so.\n",
            "\n",
            "Chunk 3 (223 chars):\n",
            "Genesis 1:31\tAnd God saw every thing that he had made, and, behold, [it was] very good. And the evening and the morning were the sixth day.\n",
            "Genesis 2:1\tThus the heavens and the earth were finished, and all the host of them.\n",
            "\n",
            "Chunk 4 (142 chars):\n",
            "Genesis 2:2\tAnd on the seventh day God ended his work which he had made; and he rested on the seventh day from all his work which he had made.\n",
            "\n",
            "Chunk 5 (142 chars):\n",
            "Genesis 2:3\tAnd God blessed the seventh day, and sanctified it: because that in it he had rested from all his work which God created and made.\n",
            "\n",
            "Chunk 6 (156 chars):\n",
            "Genesis 2:4\tThese [are] the generations of the heavens and of the earth when they were created, in the day that the LORD God made the earth and the heavens,\n",
            "\n",
            "Chunk 7 (217 chars):\n",
            "Genesis 2:5\tAnd every plant of the field before it was in the earth, and every herb of the field before it grew: for the LORD God had not caused it to rain upon the earth, and [there was] not a man to till the ground.\n",
            "\n",
            "Chunk 8 (244 chars):\n",
            "Genesis 2:6\tBut there went up a mist from the earth, and watered the whole face of the ground.\n",
            "Genesis 2:7\tAnd the LORD God formed man [of] the dust of the ground, and breathed into his nostrils the breath of life; and man became a living soul.\n",
            "\n",
            "Chunk 9 (108 chars):\n",
            "Genesis 2:8\tAnd the LORD God planted a garden eastward in Eden; and there he put the man whom he had formed.\n",
            "\n",
            "Chunk 10 (214 chars):\n",
            "Genesis 2:9\tAnd out of the ground made the LORD God to grow every tree that is pleasant to the sight, and good for food; the tree of life also in the midst of the garden, and the tree of knowledge of good and evil.\n",
            "\n",
            "Chunk 11 (248 chars):\n",
            "Genesis 2:10\tAnd a river went out of Eden to water the garden; and from thence it was parted, and became into four heads.\n",
            "Genesis 2:11\tThe name of the first [is] Pison: that [is] it which compasseth the whole land of Havilah, where [there is] gold;\n",
            "\n",
            "Chunk 12 (208 chars):\n",
            "Genesis 2:12\tAnd the gold of that land [is] good: there [is] bdellium and the onyx stone.\n",
            "Genesis 2:13\tAnd the name of the second river [is] Gihon: the same [is] it that compasseth the whole land of Ethiopia.\n",
            "\n",
            "Chunk 13 (149 chars):\n",
            "Genesis 2:14\tAnd the name of the third river [is] Hiddekel: that [is] it which goeth toward the east of Assyria. And the fourth river [is] Euphrates.\n",
            "\n",
            "Chunk 14 (216 chars):\n",
            "Genesis 2:15\tAnd the LORD God took the man, and put him into the garden of Eden to dress it and to keep it.\n",
            "Genesis 2:16\tAnd the LORD God commanded the man, saying, Of every tree of the garden thou mayest freely eat:\n",
            "\n",
            "Chunk 15 (152 chars):\n",
            "Genesis 2:17\tBut of the tree of the knowledge of good and evil, thou shalt not eat of it: for in the day that thou eatest thereof thou shalt surely die.\n",
            "\n",
            "Chunk 16 (120 chars):\n",
            "Genesis 2:18\tAnd the LORD God said, [It is] not good that the man should be alone; I will make him an help meet for him.\n",
            "\n",
            "Chunk 17 (247 chars):\n",
            "Genesis 2:19\tAnd out of the ground the LORD God formed every beast of the field, and every fowl of the air; and brought [them] unto Adam to see what he would call them: and whatsoever Adam called every living creature, that [was] the name thereof.\n",
            "\n",
            "Chunk 18 (163 chars):\n",
            "Genesis 2:20\tAnd Adam gave names to all cattle, and to the fowl of the air, and to every beast of the field; but for Adam there was not found an help meet for him.\n",
            "\n",
            "Chunk 19 (152 chars):\n",
            "Genesis 2:21\tAnd the LORD God caused a deep sleep to fall upon Adam, and he slept: and he took one of his ribs, and closed up the flesh instead thereof;\n",
            "\n",
            "Chunk 20 (255 chars):\n",
            "Genesis 2:22\tAnd the rib, which the LORD God had taken from man, made he a woman, and brought her unto the man.\n",
            "Genesis 2:23\tAnd Adam said, This [is] now bone of my bones, and flesh of my flesh: she shall be called Woman, because she was taken out of Man.\n",
            "\n",
            "Chunk 21 (211 chars):\n",
            "Genesis 2:24\tTherefore shall a man leave his father and his mother, and shall cleave unto his wife: and they shall be one flesh.\n",
            "Genesis 2:25\tAnd they were both naked, the man and his wife, and were not ashamed.\n",
            "\n",
            "Chunk 22 (194 chars):\n",
            "Genesis 3:1\tNow the serpent was more subtil than any beast of the field which the LORD God had made. And he said unto the woman, Yea, hath God said, Ye shall not eat of every tree of the garden?\n",
            "\n",
            "Chunk 23 (100 chars):\n",
            "Genesis 3:2\tAnd the woman said unto the serpent, We may eat of the fruit of the trees of the garden:\n",
            "\n",
            "Chunk 24 (232 chars):\n",
            "Genesis 3:3\tBut of the fruit of the tree which [is] in the midst of the garden, God hath said, Ye shall not eat of it, neither shall ye touch it, lest ye die.\n",
            "Genesis 3:4\tAnd the serpent said unto the woman, Ye shall not surely die:\n",
            "\n",
            "--------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ground_truth = generate_ground_truth(question, semantic_search(question, build_vectorstore(docs_for_eval, \"bge-small-en\"), 5))\n",
        "# ground_truth = f\"\"\"The Bible teaches that forgiveness is essential for spiritual growth and unity with God.\n",
        "# It emphasizes the importance of forgiving others, both within oneself and towards those who wronged them.\n",
        "# Forgiveness allows individuals to move past hurtful experiences and fosters reconciliation between people.\n",
        "# This concept is further emphasized by Jesus' teachings in Matthew 6:14-15, where He states that if one forgives others, God will forgive them as well.\n",
        "# Additionally, Paul's letter to the Ephesians highlights the divine nature of forgiveness, stating that God has given believers redemption through His blood and has forgiven them according to His grace.\n",
        "# These verses underscore the significance of forgiveness in Christian theology and its role in maintaining harmony among believers.\n",
        "# Furthermore, 2 Corinthians 2:9-11 underscores the need for forgiveness in relationships, suggesting that forgiveness can protect individuals from being used by Satan.\n",
        "# Overall, the Bible portrays forgiveness as a fundamental aspect of faith and spirituality, promoting healing and unity within communities.\n",
        "# \"\"\"\n",
        "# print(\"Generated ground truth: \\n\", ground_truth)"
      ],
      "metadata": {
        "id": "hkedXFgfM8ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk_size in chunk_sizes:\n",
        "    print(\"Chunk Size: \", chunk_size)\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=50)\n",
        "    docs = splitter.split_documents(raw_documents)\n",
        "\n",
        "    for embedding_type in embedding_methods:\n",
        "        print(\"Embedding type: \", embedding_type)\n",
        "        vectorstore, embedder = build_vectorstore(docs, embedding_type)\n",
        "\n",
        "        for model_name, pipeline_model in llm_models.items():\n",
        "            print(\"LLM model used: \", model_name)\n",
        "            print(\"beginning retrivals! \\n\")\n",
        "\n",
        "            for k_docs in doc_retrieval_counts:\n",
        "                print(\"Number of documents being retrived: \", k_docs)\n",
        "\n",
        "                for q_idx, qa in enumerate(questions_and_answers, 1):\n",
        "                    print(f\"Processing Question {q_idx}: {qa['question']}\")\n",
        "                    question = qa[\"question\"]\n",
        "                    ground_truth = qa[\"ground_truth\"]\n",
        "\n",
        "                    precomputed = {\n",
        "                    \"BM25\": bm25_search(question, docs, k_docs),\n",
        "                    \"Semantic\": semantic_search(question, vectorstore, k_docs),\n",
        "                    \"MMR\": mmr_search(question, vectorstore, k_docs)\n",
        "                    }\n",
        "\n",
        "                    for method_name in [\"BM25\", \"Semantic\", \"MMR\"]:\n",
        "                        print(\"retrieval method:\", method_name)\n",
        "                        start_time = time.time()\n",
        "                        retrieved_docs = precomputed[method_name]\n",
        "                        formatted_docs = format_retrieved_docs(retrieved_docs)\n",
        "                        llm_docs = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "                        # input_text = f\"Context: {formatted_docs}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "                        input_text = f\"\"\"You are a Bible expert. Using strictly and only the context provided below, answer the question factually in a couple of paragraphs. Do not add personal thoughts, opinions, or explanations.\n",
        "                            Context:\n",
        "                            {llm_docs}\n",
        "\n",
        "                            Question: {question}\n",
        "                            Answer: \"\"\"\n",
        "                        # response = pipeline_model(input_text)[0]['generated_text']\n",
        "                        raw_response = pipeline_model(input_text)[0]['generated_text']\n",
        "\n",
        "                        # Extract only what comes after \"Answer:\"\n",
        "                        if \"<|assistant|>\" in raw_response: # Falcon has this instead of \"Answer\"\n",
        "                            response = raw_response.split(\"<|assistant|>\")[-1].strip()\n",
        "                        elif \"Answer:\" in raw_response:\n",
        "                            response = raw_response.split(\"Answer:\")[-1].strip()\n",
        "                        else:\n",
        "                            response = raw_response.strip()\n",
        "\n",
        "                        elapsed_time = time.time() - start_time\n",
        "                        eval_scores = evaluate_response(question, response, retrieved_docs, ground_truth, embedder)\n",
        "                        results.append({\n",
        "                            \"query\": question,\n",
        "                            \"number_of_retrieved_documents\": k_docs,\n",
        "                            \"number_of_retrieved_documents_actual\": len(retrieved_docs),\n",
        "                            # \"retrieved_documents\": formatted_docs,\n",
        "                            \"retrieved_lengths\": [len(doc.page_content) for doc in retrieved_docs],\n",
        "                            \"ground_truth\": ground_truth,\n",
        "                            \"raw_response\": raw_response,\n",
        "                            \"generated_response\": response,\n",
        "                            \"chunk_size\": chunk_size,\n",
        "                            \"retrieval_method\": method_name,\n",
        "                            \"model\": model_name,\n",
        "                            \"embedding_type\": embedding_type,\n",
        "                            \"time_taken\": elapsed_time,\n",
        "                            **eval_scores\n",
        "                        })\n",
        "\n",
        "                    # Hybrid after precomputation\n",
        "                    print(\"retrieval method: Hybrid (RRF)\")\n",
        "                    start_time = time.time()\n",
        "                    retrieved_docs = hybrid_rrf_search(precomputed, k_docs)\n",
        "                    formatted_docs = format_retrieved_docs(retrieved_docs)\n",
        "                    # input_text = f\"Context: {formatted_docs}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "                    llm_docs = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "                    input_text = f\"\"\"You are a Bible expert. Using strictly and only the context provided below, answer the question factually in a couple of paragraphs. Do not add personal thoughts, opinions, or explanations.\n",
        "                        Context:\n",
        "                        {llm_docs}\n",
        "\n",
        "                        Question: {question}\n",
        "                        Answer: \"\"\"\n",
        "                    # response = pipeline_model(input_text)[0]['generated_text']\n",
        "                    raw_response = pipeline_model(input_text)[0]['generated_text']\n",
        "\n",
        "                    # Extract only what comes after \"Answer:\"\n",
        "                    if \"<|assistant|>\" in raw_response: # Falcon uses this instead of \"Answer\"\n",
        "                        response = raw_response.split(\"<|assistant|>\")[-1].strip()\n",
        "                    elif \"Answer:\" in raw_response:\n",
        "                        response = raw_response.split(\"Answer:\")[-1].strip()\n",
        "                    else:\n",
        "                        response = raw_response.strip()\n",
        "\n",
        "                    elapsed_time = time.time() - start_time\n",
        "                    eval_scores = evaluate_response(question, response, retrieved_docs, ground_truth, embedder)\n",
        "                    results.append({\n",
        "                        \"query\": question,\n",
        "                        \"number_of_retrieved_documents\": k_docs,\n",
        "                        \"number_of_retrieved_documents_actual\": len(retrieved_docs),\n",
        "                        # \"retrieved_documents\": formatted_docs,\n",
        "                        \"retrieved_lengths\": [len(doc.page_content) for doc in retrieved_docs],\n",
        "                        \"ground_truth\": ground_truth,\n",
        "                        \"raw_response\": raw_response,\n",
        "                        \"generated_response\": response,\n",
        "                        \"chunk_size\": chunk_size,\n",
        "                        \"retrieval_method\": \"Hybrid (RRF)\",\n",
        "                        \"model\": model_name,\n",
        "                        \"embedding_type\": embedding_type,\n",
        "                        \"time_taken\": elapsed_time,\n",
        "                        **eval_scores\n",
        "                    })\n",
        "\n",
        "    print(\"-----------------\")\n",
        "                # for method_name, method_func in {\n",
        "                #     \"BM25\": lambda q, d, k: bm25_search(q, d, k),\n",
        "                #     \"Semantic\": lambda q, d, k: semantic_search(q, vectorstore, k),\n",
        "                #     # \"MMR\": lambda q, d, k: mmr_search(q, vectorstore, k), # takes a long time\n",
        "                #     # \"Hybrid (RRF)\": lambda q, d, k: hybrid_rrf_search(q, d, vectorstore, k) # taking long\n",
        "                # }.items():\n",
        "\n",
        "                #     print(\"retrieval method: \", method_name)\n",
        "                #     start_time = time.time()\n",
        "                #     retrieved_docs = method_func(question, docs, k_docs)\n",
        "                #     formatted_docs = format_retrieved_docs(retrieved_docs)\n",
        "\n",
        "                #     input_text = f\"Context: {formatted_docs}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "                #     response = pipeline_model(input_text)[0]['generated_text']\n",
        "\n",
        "                #     elapsed_time = time.time() - start_time\n",
        "                #     # faithfulness, relevancy = evaluate_response(question, response, retrieved_docs, ground_truth)\n",
        "\n",
        "                #     results.append({\n",
        "                #         \"query\": question,\n",
        "                #         \"retrieved_documents\": formatted_docs,\n",
        "                #         \"generated_response\": response,\n",
        "                #         \"chunk_size\": chunk_size,\n",
        "                #         \"retrieval_method\": method_name,\n",
        "                #         \"model\": model_name,\n",
        "                #         \"embedding_type\": embedding_type,\n",
        "                #         # \"faithfulness\": faithfulness,\n",
        "                #         # \"relevancy\": relevancy,\n",
        "                #         \"time_taken\": elapsed_time,\n",
        "                #         \"num_documents\": k_docs\n",
        "                #     })\n"
      ],
      "metadata": {
        "id": "4CpPOhY2OVkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results_df = pd.DataFrame(results)\n",
        "# results_df.to_csv(\"falcon1B_Results.csv\", index=False)\n",
        "# print(results_df)\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df[[\n",
        "    \"query\",\n",
        "    \"number_of_retrieved_documents\",\n",
        "    \"retrieved_lengths\",\n",
        "    \"chunk_size\",\n",
        "    \"retrieval_method\",\n",
        "    \"model\",\n",
        "    \"embedding_type\",\n",
        "    \"time_taken\",\n",
        "    \"faithfulness\",\n",
        "    \"relevance\",\n",
        "    \"similarity\",\n",
        "    \"raw_response\",\n",
        "    \"generated_response\"\n",
        "]].to_csv(\"falcon1B_chunk256_Results.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "6XCeZMbk78kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"\\nResult {i}:\")\n",
        "    for key, value in result.items():\n",
        "        print(f\"  {key}: {value}\")\n"
      ],
      "metadata": {
        "id": "d7Ycxf7SbpMs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}